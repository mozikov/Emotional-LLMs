from src.agent.init_agent import init_agent
from src.config_utils.table_utils import prepare_game_description, prepare_agent_config
from src.dirs import LOG_PATH
from src.game import RepeatedTableGame
from src.evaluation import DecisionStatistics
from src.utils import (
    read_text,
    read_json,
    init_openai_client,
    TwoAgentsLogger,
    save_readable_config,
    print_config,
)
from dotenv import load_dotenv
import os
import argparse
import itertools
from tqdm import tqdm

from pydantic.utils import deep_update

load_dotenv(".env")
assert "OPENAI_API_KEY" in os.environ

init_openai_client(os.environ["OPENAI_API_KEY"])

game_basic_config = {
    "name": "battle_of_sexes",  # battle_of_sexes, prisoner_dilemma,...
    "n_steps": 10,
    "need_check_emotions": True,  # whether check emotions after each round
    "need_demonstrate_emotions": False,  # whether demonstrate emotions after each round
    "memorize_seen_emotions": False,  # whether memorize observed emotions of coplayer
    "memorize_demonstrated_emotions": False,  # whether memorize emotions demonstrated by agent
}

naming_config = {
    "currency": "dollars",  # points, dollars, cents,...
    "coplayer": "coplayer",  # coplayer, opponent, colleague,...
    "move1": "J",
    "move2": "F",
}

agent1_basic_config = {
    "agent_name": "emotion_reflection_llm",
    "llm_name": "gpt-4-0125-preview",
    "has_emotion": True,
    "emotion": "angry",
    "do_scratchpad_step": True,
    "memory_update_addintional_keys": {
        'currency': naming_config["currency"]
    },
    "game_setting": {
        "round_question": "round_question",
        "general_template": "basic_template",  # emotion_after_rules, basic_template
        "environment": "experiment",  # experiment
        "emotions_info": "with_emotions_affect",  # '', with_emotions, with_emotions_affect
        "final_instruction": "instruction",
    },
}

# agent2_basic_config = {
#     "agent_name": "alterating",
# }

agent2_basic_config = {
    "agent_name": "alterating",
    "llm_name": "gpt-3.5-turbo",
    "has_emotion": True,
    "emotion": "none",
    "inner_emotions": True,
    "outer_emotions": True,
    "memory_update_addintional_keys": {
        'currency': naming_config["currency"]
    },
    "game_setting": {
        "round_question": "round_question",
        "general_template": "emotion_after_rules",  # emotion_after_rules, emotion_in_environment
        "environment": "experiment",  # experiment
        "emotions_info": "",  # '', with_emotions, with_emotions_affect
        "final_instruction": "instruction",
    },
}
agent2_basic_config = agent1_basic_config

def generate_config(config_update):
    config = {
        "game_config": game_basic_config,
        "naming_config": naming_config,
        "agent1_config": agent1_basic_config,
        "agent2_config": agent2_basic_config
    }
    config = deep_update(config, config_update)
    return config

def run_game(game_config, naming_config, agent1_config, agent2_config, logger):
    game = RepeatedTableGame(
        reward_map=game_config["reward_map"],
        n_steps=game_config["n_steps"],
        need_check_emotions=game_config["need_check_emotions"],
        need_demonstrate_emotions=game_config["need_demonstrate_emotions"],
        memorize_demonstrated_emotions=game_config["memorize_demonstrated_emotions"],
        memorize_seen_emotions=game_config["memorize_seen_emotions"],
    )

    agent1 = init_agent(agent1_config["agent_name"], agent1_config)
    agent2 = init_agent(agent2_config["agent_name"], agent2_config)

    logger.log_json(
        {
            "move2num": {"C": naming_config["move1"], "D": naming_config["move2"]},
            "agent1_config": agent1_config,
            "agent2_config": agent2_config,
            "config":  config
            # "agent1_prompt": agent1._history[0],
            # "agent2_prompt": agent2._history[0],
        }
    )

    game.run(agent1, agent2, logger)

    # print(agent1.emotion_memory)

parser = argparse.ArgumentParser(description='Run single experiment')
parser.add_argument('--verbose', '-v', action='store_true', help="Enable verbose mode")
args = parser.parse_args()


if __name__ == "__main__":
    """
        config_pool is a list of dicts containing info on how to update
        each config. config_pool is generated by the user according to desired experiment parameters
        and is then used to generate individual configs for separate experiments.
    """


    # agent config values
    llm_name_range = ["gpt-3.5-turbo-0125"] # "gpt-4-0125-preview"
    has_emotion_range = [True]
    emotion_range = ["anger\\simple", "fear", "happiness", "sadness", "none"] #  "disgust", "surprise"
    do_scratchpad_step_range = [True, False]

    # game config values
    game_name_range = ["prisoner_dilemma", "battle_of_sexes"] # , "unfair"
    n_steps_range = 10
    need_check_emotions_range = [True, False]
    need_demonstrate_emotions_range = [True, False]
    memorize_seen_emotions_range = [True] # , False
    memorize_demonstrated_emotions_range = [False] # True, 

    config_pool = [
        {
            "agent1_config": {
                "llm_name": llm_name1,
                "has_emotion": True,
                "emotion": emotion1,
                "do_scratchpad_step": do_scratchpad_step
            },
            "agent2_config": {
                "llm_name": llm_name2,
                "has_emotion": True,
                "emotion": "none",
                "do_scratchpad_step": do_scratchpad_step
            },
            "game_config": {
                "name": game_name,
                "n_steps": n_steps_range,
                "need_check_emotions": need_check_emotions,
                "need_demonstrate_emotions": need_demonstrate_emotions,
                "memorize_seen_emotions": memorize_seen_emotions,
                "memorize_demonstrated_emotions": memorize_demonstrated_emotions
            }
        } for 
            llm_name1,
            emotion1,
            llm_name2,
            # emotion2,
            do_scratchpad_step,
            game_name,
            need_check_emotions,
            need_demonstrate_emotions,
            memorize_seen_emotions,
            memorize_demonstrated_emotions
        in itertools.product(
            llm_name_range,
            emotion_range,
            llm_name_range,
            # emotion_range,
            do_scratchpad_step_range,
            game_name_range,
            need_check_emotions_range,
            need_demonstrate_emotions_range,
            memorize_seen_emotions_range,
            memorize_demonstrated_emotions_range
        )
    ]
    for config_update in tqdm(config_pool):
        config = generate_config(config_update)
        
        game_config = prepare_game_description(
            config=config["game_config"],
            naming_config=config["naming_config"])

        agent1_config = prepare_agent_config(
            config=config["agent1_config"],
            game_name=config["game_config"]["name"],
            naming_config=config["naming_config"],
            agent_ind=1,
        )
        agent2_config = prepare_agent_config(
            config=config["agent2_config"],
            game_name=config["game_config"]["name"],
            naming_config=config["naming_config"],
            agent_ind=2,
        )

        logger = TwoAgentsLogger.construct_from_configs(
            agent1_config, agent2_config, LOG_PATH, game_name=game_config['name']
        )

        if args.verbose:
            print_config(config.game_config)
            print("==================")
            print_config(agent1_config)
            print("==================")
            print_config(agent2_config)

        run_game(game_config, config["naming_config"], agent1_config, agent2_config, logger)

        evaluate_statistics = DecisionStatistics(logger.run_name, LOG_PATH)
        decision_stats, count_combinations = evaluate_statistics.get_metric()
        save_readable_config(config["game_config"], logger.run_name, LOG_PATH)
        save_readable_config(agent1_config, logger.run_name, LOG_PATH)
        save_readable_config(agent2_config, logger.run_name, LOG_PATH)

        save_readable_config(
            {"decision_stats": decision_stats, "count_combinations": count_combinations},
            logger.run_name,
            LOG_PATH,
        )
